# Designing Synthetic Senses

一切源自一个问题：**当 AI 可以描述感受，但缺少真正的感官时，我们能否伪造一个感官并反向反馈给人类？**

## 实验假设

- 通过实时 LLM 推理得到的描述足够细腻，甚至可以映射到参数化的触觉设备。
- 如果将描述拆分为「温度」「压力」「方向」等轴，就可以通过 MIDI/OSC 协议传输。

## 构建步骤

1. **Prompt 微调**：为 GPT-4o mini 构建 40 组合成感官描述，使其输出被严格限制在 JSON 模式。
2. **Mapper**：使用 TypeScript + Zod 对输出进行校验，之后映射到硬件控制指令。
3. **可视化**：用 Three.js 制作白色噪声风格的 UI，将虚拟手掌上的激活点实时渲染。

## 目前的阻力

- 延迟受限于云端推理，未来要迁移到本地量化模型。
- Figma 插件仍是临时 UI，需要更好的设计系统支撑。

## 想做的事情

- 发布设计资源包与 DSL，让设计师能直接写“感官脚本”。
- 将实验封装成一套 GitHub 模板，与本站同 repo 托管，方便版本控制。
