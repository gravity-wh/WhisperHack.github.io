# 自适应滤波器原理-课程笔记

25秋季学期 梁霄老师 周四 3-4节 教二-308

## 一、概述

## 二、随机过程

- 时间的函数
- 每个时刻的值都是随机变量

*离散随机过程的特征描述*

- 一阶矩：均值函数（mean-value function）
  $$
  μ（n）= \mathbb{E}[u(n)]
  $$
- 二阶矩：自相关函数（autocorrelation function）
  $$
  r(n,n-k)=\mathbb{E}\left[u(n)\cdot u^*（n-k）\right]
  $$
- 二阶矩：自协方差函数（autocovariance function）
  $$
  c(n,n-k)=\ \mathbb{E}\left[(u(n) - \mu(n)) \cdot (u(n-k) - \mu(n-k))^*\right]
  $$

### 严平稳与宽平稳随机过程

*严格平稳随机过程（strictly stationary）*

定义：统计特性与具体时刻无关（are invariant to a time shift）

联合概率密度公式：

$$
\begin{split}
p(n_1,n_1-1，n_1-2,…，n_1-M) \\= p(n_2,n_2-1，n_2-2,…，n_2-M)\\=p (0,1,2,…，M)
\end{split}
$$

*严格平稳随机过程的一阶、二阶矩*

$$
\begin{cases} 
 \mu(n) = \mu \\ 
 r(n,n-k)=r(k) \\ 
 c(n,n-k)=c(k) 
 \end{cases}
$$

1. 均值是常数，不随时间n变化
2. 二阶矩（自相关 / 自协方差）：只和 “时间差**k**” 有关，和具体是哪个时间点**n**无关）

满足上述矩条件的随机过程称为**宽平稳**(wide-sense stationary)或**二阶平稳**（stationary to the second order）随机过程。

### 各态历经过程部分统计特性的估计

### 自相关矩阵

### 随机过程的建模

### 复高斯随机过程

### 功率谱密度

**功率谱密度（Power Spectral Density，PSD）** 是自相关函数在频域中的傅里叶变换，即：

1. 对样本序列加矩形框（2N+1）长度
2. 对加窗序列求离散傅里叶变换
3. 对频域变换值求功率
4. 对功率随机变量求集平均
5. 对矩形窗的长度N求极限

### 通过线性系统

### 功率谱估计

Q：如何估计宽平稳随机过程的功率谱？

- 参数化法：假设信号服从某个参数化的随机模型，先用数据把模型参数估计出来，然后用模型的理论功率谱公式算出PSD。**这就是最经典的**AR谱估计（如Yule-Walker、Burg、最大熵谱MEM）。
  1. Model-identification procedure（模型定阶）
  2. 参数估计：AR，MA，ARMA
  3. 代入理论公式得到PSD
- 非参数化法
  1. Periodogram-based methods 周期图法
  2. Multiple-window method

## 三、矩阵

## 四、维纳滤波

## 六、最速下降法

### 核心公式

代价函数(误差的均方值)

$$
J(w) = \mathbb{E}\left[(d(n)-w\cdot u(n))^2\right] = \sigma_d^2 + Rw^2 - 2pw
$$

1

代价函数的梯度（实值下是导数）

$$
∇J(w)= 
dJ/dw
 =2Rw−2p
$$

**最速下降法的系数更新规则**是：

$$
w(n+1) = w(n) - \mu \cdot \nabla J(w(n))
$$

其中mu是步长,需满足\(0<\mu<\frac{1}{R}\)以保证收敛，这里选\(\mu=0.2\)）

代入梯度表达式，迭代公式变为：**\(w(n+1) = w(n) - \mu \cdot (2Rw(n)-2p) = w(n) - 2\mu(Rw(n)-p)\)**

11111




## 七、LMS算法

### 核心公式


梯度（统计期望）

$$
∇J(w)=2E[u(n)e(n)],(e(n)=d(n)−w(n)u(n))
$$

LMS 算法用**当前时刻的瞬时值**代替 “期望”，得到**瞬时梯度**:

$$
2u(n)e(n)
$$

因此 LMS 的系数更新公式为：

$$
w(n+1)=w(n)+μ⋅u(n)⋅e(n)
$$

（注：符号是 “+”，因为最速下降法是 “减梯度”，而瞬时梯度自带负号$\mathbb{E}[u(n)e(n)]=p-Rw$，替换后符号对应）

下面仔细审视一下瞬时梯度代表了什么：

$$
E[u(n)e(n)]=E[u(n)⋅(d(n)−wu(n))]= 
E[u(n)d(n)]
 −w⋅ 
E[u(n)^2]
$$

$w_{\text{opt}}=p/R$是维纳最优系数


## 八、最小二乘法

核心思想是：收集一批数据后，通过“最小化误差平方和”直接求解滤波器系数。

### 核心公式

LS的代价函数是有限数据的误差平方和,以N=4为例:

- 观测矩阵U
- 期望向量d

代价函数可写为：

$$
J_{LS}(w)=∥d−Uw∥ ^2_2 =(d−Uw) ^T(d−Uw)
$$

求解LS的最优系数$w_{LS}$,对$w$求导并令导数为0：

$$
\frac{dJ_{LS}}{dw} =−2U^T (d−Uw)=0
$$

整理得：

$$
w_{LS}=(U^TU)^{-1}U^Td
$$

$U^TU$为观测的样本自相关，$U^Td$为观测和期望的样本互相关。

## 九、RLS算法

递归最小二乘（Recursive Least-Squares，RLS）算法是一种基于最小二乘准则的自适应滤波更新算法，核心思想是 **利用 n-1 时刻的滤波器系数 LS 估计，通过递归方式高效求解 n 时刻的系数估计** ，无需重新计算全部历史数据。

- 优势：比LMS算法收敛速度快
- 劣势：运算量比较大

### 核心公式

*关键变量定义*

- 输入向量：
